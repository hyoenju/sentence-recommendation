{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "movie = pickle.load( open( \"movie_tweet_2.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "movie_tweet = copy(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for idx, data in enumerate(movie_tweet):\n",
    "    title = data['title'].lower()\n",
    "    movie_conversation = []\n",
    "    for tweet in data['tweet']:\n",
    "        cleaned_tweet = re.sub('[^A-Za-z0-9_\\s]', \"\", tweet.lower())\n",
    "        tweet_list = cleaned_tweet.split(\" \")\n",
    "        if title in tweet_list:\n",
    "            tweet_list.remove(title)\n",
    "        if '' in tweet_list:\n",
    "            space_count = tweet_list.count('')\n",
    "            for _ in range(space_count):\n",
    "                tweet_list.remove('')\n",
    "    \n",
    "        movie_conversation.append(' '.join(tweet_list))\n",
    "    movie_tweet[idx]['tweet'] = movie_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.tag import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "st = PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "tweet_token = copy(movie_tweet)\n",
    "\n",
    "for idx, data in enumerate(movie_tweet):\n",
    "    tweet_data = []\n",
    "    for tweet in data['tweet']:\n",
    "#         tweet_data.append(pos_tag(word_tokenize(tweet)))\n",
    "        token_and_stem = [st.stem(i) for i in word_tokenize(tweet)]\n",
    "        filtered_words = [i for i in token_and_stem if i not in stop]    \n",
    "        \n",
    "        tweet_data.append(filtered_words)\n",
    "        \n",
    "    tweet_token[idx]['tweet'] = tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(tweet_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for i in df.tweet:\n",
    "    for j in i:\n",
    "        vocab += j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "#print(collections.Counter(vocab).most_common(3000), \"\\n\")\n",
    "most_common_vocab = collections.Counter(vocab).most_common(5000)\n",
    "\n",
    "_vocab = [word for word, common in most_common_vocab]\n",
    "\n",
    "unknown_token = 'UNKNOWN_TOKEN'\n",
    "_vocab.append(unknown_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_dict = {word:idx for idx, word in enumerate(_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['made', 'ref', 'help', 'peopl', 'draw', 'fireemblemhero'],\n",
       " ['ref', 'use', 'make', 'tutori'],\n",
       " ['goddess', 'thank', 'yiu', 'much'],\n",
       " ['np', 'gotchu', '3']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = copy(df.tweet)\n",
    "\n",
    "index_to_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row, thread in enumerate(index_to_word):\n",
    "    for num ,tweet in enumerate(thread):\n",
    "        conversation_list = []\n",
    "        for idx, word in enumerate(tweet):\n",
    "#             one_hot_tweet  = [0 for _ in range(len(vocab_dict))]\n",
    "#             print(vocab_dict[word])\n",
    "#             one_hot_tweet[vocab_dict[word]] = 1\n",
    "#         conversation_list.append(one_hot_tweet)\n",
    "            if word in vocab_dict.keys():\n",
    "                index_to_word[row][num][idx] = vocab_dict[word]\n",
    "            else:\n",
    "                index_to_word[row][num][idx] = vocab_dict[unknown_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_index = copy(df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_dict = {title:idx for idx, title in enumerate(set(title_index))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, title in enumerate(title_index):\n",
    "    title_index[idx] = title_dict[title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commando\n"
     ]
    }
   ],
   "source": [
    "for a, b in title_dict.items():\n",
    "    if b==1536:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_word_size = 0\n",
    "max_conversation_size = 0\n",
    "\n",
    "for conversation_list in index_to_word:\n",
    "    if len(conversation_list) > max_conversation_size:\n",
    "        max_conversation_size = len(conversation_list)\n",
    "    for word_list in conversation_list:\n",
    "        if len(word_list) > max_word_size:\n",
    "            max_word_size = len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 27)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conversation_size, max_word_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_VALUE = 10000\n",
    "\n",
    "for conversation_idx, conversation_list in enumerate(index_to_word):\n",
    "    if len(conversation_list) < max_conversation_size:\n",
    "        default_list_size = max_conversation_size-len(conversation_list)\n",
    "        for _ in range(default_list_size):\n",
    "            default_list = [DEFAULT_VALUE for i in range(max_word_size)]\n",
    "            index_to_word[conversation_idx].append(default_list)\n",
    "            \n",
    "    for word_list_idx, word_list in enumerate(conversation_list):\n",
    "        if len(word_list) < max_word_size:\n",
    "            current_word_list_size = len(word_list)\n",
    "            empty_word_space_size = max_word_size - current_word_list_size\n",
    "            for _ in range(empty_word_space_size):\n",
    "                index_to_word[conversation_idx][word_list_idx].append(DEFAULT_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = []\n",
    "for i in index_to_word:\n",
    "    row_data = []\n",
    "    for j in i:\n",
    "        row_data+= j\n",
    "    x_data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7f64709b7dd8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(title_dict)\n",
    "\n",
    "#X = tf.placeholder(tf.float32, [None, max_conversation_size, max_word_size])\n",
    "X = tf.placeholder(tf.float32, [None, max_conversation_size])\n",
    "Y = tf.placeholder(tf.int32, [None, n_classes])\n",
    "# Y = tf.placeholder(tf.int32, [n_classes])\n",
    "\n",
    "rnn_size = n_classes\n",
    "num_layers = 4\n",
    "time_step_size = max_conversation_size\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_size)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell]*num_layers)\n",
    "state = tf.zeros([batch_size, cell.state_size])\n",
    "X_split = tf.split(0, time_step_size, X)\n",
    "outputs, state = tf.nn.rnn(cell, X_split , state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'RNN/MultiRNNCell/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_1/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_2/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_3/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_4/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_5/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_6/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_7/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>, <tf.Tensor 'RNN/MultiRNNCell_8/Cell3/BasicLSTMCell/mul_2:0' shape=(1, 1847) dtype=float32>]\n",
      "\n",
      "\n",
      "Tensor(\"RNN/concat_8:0\", shape=(1, 14776), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(\"\\n\")\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])\n",
    "targets = tf.reshape(Y, [-1])\n",
    "weights = tf.ones(time_step_size*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "    [logits], [targets],[weights])\n",
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "train_op = tf.train.AdamOptimizer(0.01, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: 0        837\n1        837\n2        837\n3        837\n4        837\n5        837\n6        837\n7        837\n8        837\n9        837\n10       837\n11       837\n12       837\n13       837\n14       837\n15         4\n16       762\n17       467\n18       467\n19       467\n20       467\n21       467\n22       467\n23       467\n24       916\n25       198\n26      1338\n27      1338\n28      1338\n29      1338\n        ... \n7889     194\n7890     194\n7891     194\n7892     194\n7893    1358\n7894    1358\n7895    1358\n7896    1358\n7897     994\n7898     994\n7899     994\n7900     994\n7901     994\n7902     994\n7903     994\n7904     994\n7905     994\n7906     994\n7907     152\n7908     152\n7909     152\n7910     519\n7911     519\n7912     618\n7913    1418\n7914    1418\n7915    1418\n7916    1418\n7917    1418\n7918    1418\nName: title, dtype: object - got shape [7919], but wanted [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 as_ref=input_arg.is_ref)\n\u001b[0m\u001b[0;32m    456\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    161\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 162\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape)\u001b[0m\n\u001b[0;32m    361\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument must be a dense tensor: 0        837\n1        837\n2        837\n3        837\n4        837\n5        837\n6        837\n7        837\n8        837\n9        837\n10       837\n11       837\n12       837\n13       837\n14       837\n15         4\n16       762\n17       467\n18       467\n19       467\n20       467\n21       467\n22       467\n23       467\n24       916\n25       198\n26      1338\n27      1338\n28      1338\n29      1338\n        ... \n7889     194\n7890     194\n7891     194\n7892     194\n7893    1358\n7894    1358\n7895    1358\n7896    1358\n7897     994\n7898     994\n7899     994\n7900     994\n7901     994\n7902     994\n7903     994\n7904     994\n7905     994\n7906     994\n7907     152\n7908     152\n7909     152\n7910     519\n7911     519\n7912     618\n7913    1418\n7914    1418\n7915    1418\n7916    1418\n7917    1418\n7918    1418\nName: title, dtype: object - got shape [7919], but wanted [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b374527d9b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \"\"\"\n\u001b[0;32m   1382\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[1;32m-> 1383\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   1384\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[1;31m# What type does convert_to_tensor think it has?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m             observed = ops.convert_to_tensor(values,\n\u001b[1;32m--> 459\u001b[1;33m                                              as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[0;32m    460\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[0;32m    461\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfuncs_at_priority\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    177\u001b[0m                                          as_ref=False):\n\u001b[0;32m    178\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/ops/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    160\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 162\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m/home/hyeonju/anaconda3/envs/ml_python/lib/python3.4/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape)\u001b[0m\n\u001b[0;32m    360\u001b[0m                          \"\"\" - got shape %s, but wanted %s.\"\"\" % (\n\u001b[0;32m    361\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Argument must be a dense tensor: 0        837\n1        837\n2        837\n3        837\n4        837\n5        837\n6        837\n7        837\n8        837\n9        837\n10       837\n11       837\n12       837\n13       837\n14       837\n15         4\n16       762\n17       467\n18       467\n19       467\n20       467\n21       467\n22       467\n23       467\n24       916\n25       198\n26      1338\n27      1338\n28      1338\n29      1338\n        ... \n7889     194\n7890     194\n7891     194\n7892     194\n7893    1358\n7894    1358\n7895    1358\n7896    1358\n7897     994\n7898     994\n7899     994\n7900     994\n7901     994\n7902     994\n7903     994\n7904     994\n7905     994\n7906     994\n7907     152\n7908     152\n7909     152\n7910     519\n7911     519\n7912     618\n7913    1418\n7914    1418\n7915    1418\n7916    1418\n7917    1418\n7918    1418\nName: title, dtype: object - got shape [7919], but wanted []."
     ]
    }
   ],
   "source": [
    "x_data = tf.Variable(x_data)\n",
    "y_data = tf.reshape(tf.reshape(title_index, [-1]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    result = sess.run(train_op, feed_dict={X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
